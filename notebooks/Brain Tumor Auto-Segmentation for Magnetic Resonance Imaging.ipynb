{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXW9aGLroXsV"
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/2652/1*eTkBMyqdg9JodNcG_O4-Kw.jpeg\" width=\"100%\">\n",
    "\n",
    "[Image Source](https://medium.com/stanford-ai-for-healthcare/its-a-no-brainer-deep-learning-for-brain-mr-images-f60116397472)\n",
    "\n",
    "# Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTHrazBFcAtl"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:11.197002Z",
     "start_time": "2020-03-08T01:28:16.130730Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "sJz-IbUycEhT",
    "outputId": "49ae7bfe-c506-4b1a-c6ea-7a831bedfc09"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTg4vp-Eo86-"
   },
   "source": [
    "<a name=\"1-3\"></a>\n",
    "## 1.3 Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:36.462907Z",
     "start_time": "2020-03-08T01:29:36.458910Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "AoW-WFWNW0cN"
   },
   "outputs": [],
   "source": [
    "# set home directory and data directory\n",
    "HOME_DIR = \"./BraTS-Data/\"\n",
    "DATA_DIR = HOME_DIR\n",
    "\n",
    "def load_case(image_nifty_file, label_nifty_file):\n",
    "    # load the image and label file, get the image content and return a numpy array for each\n",
    "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
    "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:41.377380Z",
     "start_time": "2020-03-08T01:29:38.869873Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "ihLR2ZD-W0cU",
    "outputId": "dcf534ac-8c15-46d5-9851-a0fe35e05411"
   },
   "outputs": [],
   "source": [
    "# visualize an example\n",
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "image = util.get_labeled_image(image, label)\n",
    "\n",
    "util.plot_image_grid(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:46.121069Z",
     "start_time": "2020-03-08T01:29:42.475071Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "TJubVx44W0cf",
    "outputId": "a5ac10ef-be99-491f-cc04-1ace92434e25"
   },
   "outputs": [],
   "source": [
    "# GIF for iterating over each axis\n",
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "util.visualize_data_gif(util.get_labeled_image(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dulCuzOnW0ch"
   },
   "source": [
    "<a name=\"1-4\"></a>\n",
    "## 1.4 Data Preprocessing using patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H8GLemPeW0cj"
   },
   "source": [
    "<a name=\"1-4-1\"></a>\n",
    "### 1.4.1 Sub-volume Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:46.136073Z",
     "start_time": "2020-03-08T01:29:46.123072Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "AXKV1epOSuUl"
   },
   "outputs": [],
   "source": [
    "def get_sub_volume(image, label, \n",
    "                   orig_x = 240, orig_y = 240, orig_z = 155, \n",
    "                   output_x = 160, output_y = 160, output_z = 16,\n",
    "                   num_classes = 4, max_tries = 1000, \n",
    "                   background_threshold=0.95):\n",
    "\n",
    "    # Initialize features and labels with `None`\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    tries = 0\n",
    "    \n",
    "    while tries < max_tries:\n",
    "        # randomly sample sub-volume by sampling the corner voxel\n",
    "        # hint: make sure to leave enough room for the output dimensions!\n",
    "        start_x = np.random.randint(0 , orig_x - output_x + 1)\n",
    "        start_y = np.random.randint(0 , orig_y - output_y + 1)\n",
    "        start_z = np.random.randint(0 , orig_z - output_z + 1)\n",
    "\n",
    "        # extract relevant area of label\n",
    "        y = label[start_x: start_x + output_x,\n",
    "                  start_y: start_y + output_y,\n",
    "                  start_z: start_z + output_z]\n",
    "        \n",
    "        # One-hot encode the categories.\n",
    "        # This adds a 4th dimension, 'num_classes'\n",
    "        # (output_x, output_y, output_z, num_classes)\n",
    "        y = keras.utils.to_categorical(y, num_classes = num_classes)\n",
    "\n",
    "        # compute the background ratio\n",
    "        bgrd_ratio = np.sum(y[:,:,:,0]) / (output_x * output_y * output_z)\n",
    "\n",
    "        # increment tries counter\n",
    "        tries += 1\n",
    "\n",
    "        # if background ratio is below the desired threshold,\n",
    "        # use that sub-volume.\n",
    "        # otherwise continue the loop and try another random sub-volume\n",
    "        if bgrd_ratio < background_threshold:\n",
    "\n",
    "            # make copy of the sub-volume\n",
    "            X = np.copy(image[start_x: start_x + output_x,\n",
    "                              start_y: start_y + output_y,\n",
    "                              start_z: start_z + output_z, :])\n",
    "            \n",
    "            # change dimension of X\n",
    "            # from (x_dim, y_dim, z_dim, num_channels)\n",
    "            # to (num_channels, x_dim, y_dim, z_dim)\n",
    "            X = np.moveaxis(X,3,0)\n",
    "\n",
    "            # change dimension of y\n",
    "            # from (x_dim, y_dim, z_dim, num_classes)\n",
    "            # to (num_classes, x_dim, y_dim, z_dim)\n",
    "            y = np.moveaxis(y,3,0)\n",
    "            \n",
    "            # take a subset of y that excludes the background class\n",
    "            # in the 'num_classes' dimension\n",
    "            y = y[1:, :, :, :]\n",
    "    \n",
    "            return X, y\n",
    "\n",
    "    # if we've tried max_tries number of samples\n",
    "    # Give up in order to avoid looping forever.\n",
    "    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:46.367069Z",
     "start_time": "2020-03-08T01:29:46.224070Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FfL0EzHrYs4A",
    "outputId": "30916a33-23dc-4800-9847-549cf4102efa"
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "image = np.zeros((4, 4, 3, 1))\n",
    "label = np.zeros((4, 4, 3))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for k in range(3):\n",
    "            image[i, j, k, 0] = i*j*k\n",
    "            label[i, j, k] = k\n",
    "\n",
    "print(\"image:\")\n",
    "for k in range(3):\n",
    "    print(f\"z = {k}\")\n",
    "    print(image[:, :, k, 0])\n",
    "print(\"\\n\")\n",
    "print(\"label:\")\n",
    "for k in range(3):\n",
    "    print(f\"z = {k}\")\n",
    "    print(label[:, :, k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Extracting (2, 2, 2) sub-volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:46.456070Z",
     "start_time": "2020-03-08T01:29:46.368070Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_image, sample_label = get_sub_volume(image, \n",
    "                                            label,\n",
    "                                            orig_x=4, \n",
    "                                            orig_y=4, \n",
    "                                            orig_z=3,\n",
    "                                            output_x=2, \n",
    "                                            output_y=2, \n",
    "                                            output_z=2,\n",
    "                                            num_classes = 3)\n",
    "\n",
    "print(\"Sampled Image:\")\n",
    "for k in range(2):\n",
    "    print(\"z = \" + str(k))\n",
    "    print(sample_image[0, :, :, k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "\n",
    "```Python\n",
    "Sampled Image:\n",
    "z = 0\n",
    "[[0. 2.]\n",
    " [0. 3.]]\n",
    "z = 1\n",
    "[[0. 4.]\n",
    " [0. 6.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:46.583069Z",
     "start_time": "2020-03-08T01:29:46.457069Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Sampled Label:\")\n",
    "for c in range(2):\n",
    "    print(\"class = \" + str(c))\n",
    "    for k in range(2):\n",
    "        print(\"z = \" + str(k))\n",
    "        print(sample_label[c, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:49.157586Z",
     "start_time": "2020-03-08T01:29:47.726586Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "otA9p2lRW0cu",
    "outputId": "e0888053-f1ca-4afd-e946-2416446d423e"
   },
   "outputs": [],
   "source": [
    "# looking to a candidate patch\n",
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\n",
    "X, y = get_sub_volume(image, label)\n",
    "# enhancing tumor is channel 2 in the class label\n",
    "# you can change indexer for y to look at different classes\n",
    "util.visualize_patch(X[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEjatQCQW0cy"
   },
   "source": [
    "<a name=\"1-4-2\"></a>\n",
    "### 1.4.2 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:49.164587Z",
     "start_time": "2020-03-08T01:29:49.159584Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kNht6sVLW0c0"
   },
   "outputs": [],
   "source": [
    "def standardize(image):\n",
    "    \n",
    "    # initialize to array of zeros, with same shape as the image\n",
    "    standardized_image = np.zeros(image.shape)\n",
    "\n",
    "    # iterate over channels\n",
    "    for c in range(image.shape[0]):\n",
    "        # iterate over the `z` dimension\n",
    "        for z in range(image.shape[3]):\n",
    "            # get a slice of the image \n",
    "            # at channel c and z-th dimension `z`\n",
    "            image_slice = image[c,:,:,z]\n",
    "\n",
    "            # subtract the mean from image_slice\n",
    "            centered = image_slice - np.mean(image_slice)\n",
    "            \n",
    "            # divide by the standard deviation (only if it is different from zero)\n",
    "            centered_scaled = centered / np.std(centered)\n",
    "\n",
    "            # update  the slice of standardized image\n",
    "            # with the scaled centered and scaled image\n",
    "            standardized_image[c, :, :, z] = centered_scaled\n",
    "\n",
    "    return standardized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:51.702267Z",
     "start_time": "2020-03-08T01:29:51.670269Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xt1DAVhRW0c5",
    "outputId": "e5dee9cc-5183-4ede-88b1-5cb0ccb7a26b"
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "X_norm = standardize(X)\n",
    "print(\"standard deviation for a slice should be 1.0\")\n",
    "print(f\"stddv for X_norm[0, :, :, 0]: {X_norm[0,:,:,0].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:53.531889Z",
     "start_time": "2020-03-08T01:29:53.340902Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "XcMiq-3FOYHe",
    "outputId": "b910aa87-4499-473d-9779-42b30a7a40bc"
   },
   "outputs": [],
   "source": [
    "# Visualizing patch\n",
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "# 2 Model: 3D U-Net\n",
    "\n",
    "Now let's build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0tVtbIshBXq"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "# 3 Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOWndz7GecSh"
   },
   "source": [
    "<a name=\"3-1\"></a>\n",
    "## 2.1 Dice Similarity Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:29:58.009018Z",
     "start_time": "2020-03-08T01:29:58.004988Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DRZUNCaM_9x7"
   },
   "outputs": [],
   "source": [
    "def single_class_dice_coefficient(y_true, y_pred, axis=(0, 1, 2), \n",
    "                                  epsilon=0.00001):\n",
    "    \n",
    "    dice_numerator = 2 * np.sum(y_true * y_pred, axis = axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true,axis= axis) + K.sum(y_pred, axis= axis) + epsilon\n",
    "    dice_coefficient = dice_numerator / dice_denominator\n",
    "\n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:30:00.603988Z",
     "start_time": "2020-03-08T01:29:59.198014Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "XOugSRoF_8jN",
    "outputId": "a0a1b9ff-aa7b-46eb-96a3-7ee443ea9831"
   },
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "sess = K.get_session()\n",
    "#sess = tf.compat.v1.Session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.eye(2), -1)\n",
    "    label = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "\n",
    "    print(\"Test Case #1\")\n",
    "    print(\"pred:\")\n",
    "    print(pred[:, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[:, :, 0])\n",
    "\n",
    "    # choosing a large epsilon to help check for implementation errors\n",
    "    dc = single_class_dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Test Case #2\")\n",
    "    pred = np.expand_dims(np.eye(2), -1)\n",
    "    label = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[:, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[:, :, 0])\n",
    "\n",
    "    # choosing a large epsilon to help check for implementation errors\n",
    "    dc = single_class_dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice_coefficient: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1s3uVww0C01C"
   },
   "source": [
    "### Dice Coefficient for Multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:30:02.777039Z",
     "start_time": "2020-03-08T01:30:02.774035Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r0G9ND3_W0dC"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n",
    "                     epsilon=0.00001):\n",
    "    \n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred , axis = axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true, axis = axis ) + K.sum(y_pred, axis = axis) + epsilon\n",
    "    dice_coefficient = K.mean(dice_numerator/dice_denominator)\n",
    "\n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:30:03.800562Z",
     "start_time": "2020-03-08T01:30:03.627565Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "bQi8Trze4jGR",
    "outputId": "d07e46f0-bc8e-4379-dc4d-46576a2911b5"
   },
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "    print(\"Test Case #1\")\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(label, pred, epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Test Case #2\")\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    print(\"Test Case #3\")\n",
    "    pred = np.zeros((2, 2, 2, 1))\n",
    "    pred[0, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    pred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    \n",
    "    label = np.zeros((2, 2, 2, 1))\n",
    "    label[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "    label[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(\"class = 0\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(pred[1, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(\"class = 0\")\n",
    "    print(label[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(label[1, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(f\"dice coefficient: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UFpujr1Mo8m"
   },
   "source": [
    "<a name=\"3-2\"></a>\n",
    "## 3.2 Soft Dice Loss\n",
    "\n",
    "### Multi-Class Soft Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:30:07.313338Z",
     "start_time": "2020-03-08T01:30:07.309342Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aMR9KO7mHVl5"
   },
   "outputs": [],
   "source": [
    "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n",
    "                   epsilon=0.00001):\n",
    "\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred , axis= axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true ** 2, axis= axis) + K.sum(y_pred ** 2 , axis = axis) + epsilon\n",
    "    dice_loss = 1 - K.mean(dice_numerator / dice_denominator)\n",
    "\n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:30:08.094307Z",
     "start_time": "2020-03-08T01:30:07.895306Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "FuUigtIO9QVh",
    "outputId": "d534083d-9b40-40e5-8e9b-f1bcd3a609c2"
   },
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "    print(\"Test Case #1\")\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss:{dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "    \n",
    "    print(\"Test Case #2\")\n",
    "    pred = np.expand_dims(np.expand_dims(0.5*np.eye(2), 0), -1)\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "    \n",
    "    print(\"Test Case #3\")\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "    print(\"Test Case #4\")\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    pred[0, 0, 1, 0] = 0.8\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "    \n",
    "    print(\"Test Case #5\")\n",
    "    pred = np.zeros((2, 2, 2, 1))\n",
    "    pred[0, :, :, :] = np.expand_dims(0.5*np.eye(2), -1)\n",
    "    pred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    pred[1, 0, 1, 0] = 0.8\n",
    "\n",
    "    label = np.zeros((2, 2, 2, 1))\n",
    "    label[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "    label[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(\"class = 0\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(pred[1, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(\"class = 0\")\n",
    "    print(label[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(label[1, :, :, 0])\n",
    "\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss: {dc.eval():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 6\n",
    "pred = np.array([\n",
    "                    [\n",
    "                        [ \n",
    "                            [1.0, 1.0], [0.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 1.0]\n",
    "                        ]\n",
    "                    ],\n",
    "                    [\n",
    "                        [ \n",
    "                            [1.0, 1.0], [0.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 1.0]\n",
    "                        ]\n",
    "                    ],\n",
    "                  ])\n",
    "label = np.array([\n",
    "                    [\n",
    "                        [ \n",
    "                            [1.0, 0.0], [1.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 0.0]\n",
    "                        ]\n",
    "                    ],\n",
    "                    [\n",
    "                        [ \n",
    "                            [0.0, 0.0], [0.0, 0.0]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1.0, 0.0], [0.0, 0.0]\n",
    "                        ]\n",
    "                    ]\n",
    "                  ])\n",
    "\n",
    "sess = K.get_session()\n",
    "print(\"Test case #6\")\n",
    "with sess.as_default() as sess:\n",
    "    dc = soft_dice_loss(pred, label, epsilon=1)\n",
    "    print(f\"soft dice loss\",dc.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HXdsoV9OVEV"
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "# 4 Create and Train the model\n",
    "\n",
    "Now, we can create the model!\n",
    "\n",
    "We'll use the `unet_model_3d` function in `utils`\n",
    "- This creates the model architecture and compiles the model with the specified loss functions and metrics. \n",
    "- Check out function `util.unet_model_3d(loss_function)` in the `util.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = util.unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQ-JvVotW0dS"
   },
   "source": [
    "<a name=\"4-1\"></a>\n",
    "## 4.1 Training on a Large Dataset\n",
    "\n",
    "- I have pre-processed the entire dataset into patches and stored the patches in the [`h5py`](http://docs.h5py.org/en/stable/) format.\n",
    "- I also wrote a custom Keras [`Sequence`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) class which can be used as a `Generator` for the keras model to train on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcBeF80jf54b"
   },
   "outputs": [],
   "source": [
    "base_dir = HOME_DIR + \"processed/\"\n",
    "\n",
    "with open(base_dir + \"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "# Get generators for training and validation sets\n",
    "train_generator = util.VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
    "valid_generator = util.VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
    "\n",
    "steps_per_epoch = 20\n",
    "n_epochs=10\n",
    "validation_steps = 20\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=n_epochs,\n",
    "        use_multiprocessing=True,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Oq1qG5UW0dY"
   },
   "source": [
    "<a name=\"4-2\"></a>\n",
    "## 4.2 Loading a Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = HOME_DIR + \"processed/\"\n",
    "with open(base_dir + \"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "    \n",
    "# Get generators for training and validation sets\n",
    "train_generator = util.VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
    "valid_generator = util.VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYJ3cdSGeR5l"
   },
   "outputs": [],
   "source": [
    "model.load_weights(HOME_DIR + \"model_pretrained.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22JSeC5yOnty"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "# 5 Evaluation\n",
    "\n",
    "Now we will evaluate its performance on scans from validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjK9oMJ3iEeW"
   },
   "source": [
    "<a name=\"5-1\"></a>\n",
    "## 5.1 Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the validation set for testing\n",
    "# val_loss, val_dice = model.evaluate_generator(valid_generator)\n",
    "\n",
    "# print(f\"validation soft dice loss: {val_loss:.4f}\")\n",
    "# print(f\"validation dice coefficient: {val_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGZ-GLXPiCXH"
   },
   "source": [
    "<a name=\"5-2\"></a>\n",
    "## 5.2 Patch-level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "D3Zx9gSiAhEC",
    "outputId": "4fb5d166-2dbe-4cfc-84ce-8ebab9867729"
   },
   "outputs": [],
   "source": [
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRJF6bR9i4n7"
   },
   "source": [
    "#### Add a 'batch' dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GKVqDNbjUIF"
   },
   "outputs": [],
   "source": [
    "X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=0)\n",
    "patch_pred = model.predict(X_norm_with_batch_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c11FN5SJjXxT"
   },
   "source": [
    "#### Convert prediction from probability into a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCsVNiKJBvcC"
   },
   "outputs": [],
   "source": [
    "# set threshold.\n",
    "threshold = 0.5\n",
    "\n",
    "# use threshold to get hard predictions\n",
    "patch_pred[patch_pred > threshold] = 1.0\n",
    "patch_pred[patch_pred <= threshold] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "vf6N-lzLjov4",
    "outputId": "071f06c1-a440-4267-99bf-cf261c82efff"
   },
   "outputs": [],
   "source": [
    "# Visualize original patch and groung truth alongside thresholded predications\n",
    "print(\"Patch and ground truth\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], y[2])\n",
    "plt.show()\n",
    "print(\"Patch and prediction\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], patch_pred[0, 2, :, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JAEdpA3llCJ"
   },
   "source": [
    "#### Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2ajAYw0bQ50"
   },
   "outputs": [],
   "source": [
    "def compute_class_sens_spec(pred, label, class_num):\n",
    "\n",
    "    # extract sub-array for specified class\n",
    "    class_pred = pred[class_num]\n",
    "    class_label = label[class_num]\n",
    "    \n",
    "    # compute:\n",
    "    \n",
    "    # true positives\n",
    "    tp = np.sum( (class_pred == 1) * (class_label == 1))\n",
    "\n",
    "    # true negatives\n",
    "    tn = np.sum( (class_pred == 0) * (class_label == 0))\n",
    "    \n",
    "    #false positives\n",
    "    fp = np.sum( (class_pred == 1) * (class_label == 0))\n",
    "    \n",
    "    # false negatives\n",
    "    fn = np.sum( (class_pred == 0) * (class_label == 1))\n",
    "\n",
    "    # compute sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "mcTtD1JdYnGj",
    "outputId": "b3d1b2f4-224e-4855-cd48-d53dc7a9fb04"
   },
   "outputs": [],
   "source": [
    "# TEST CASES\n",
    "pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "print(\"Test Case #1\")\n",
    "print(\"pred:\")\n",
    "print(pred[0, :, :, 0])\n",
    "print(\"label:\")\n",
    "print(label[0, :, :, 0])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Case #2\")\n",
    "\n",
    "pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "print(\"pred:\")\n",
    "print(pred[0, :, :, 0])\n",
    "print(\"label:\")\n",
    "print(label[0, :, :, 0])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we must explicity import 'display' in order for the autograder to compile the submitted code\n",
    "# Even though we could use this function without importing it, keep this import in order to allow the grader to work\n",
    "from IPython.display import display\n",
    "print(\"Test Case #3\")\n",
    "\n",
    "df = pd.DataFrame({'y_test': [1,1,0,0,0,0,0,0,0,1,1,1,1,1],\n",
    "                   'preds_test': [1,1,0,0,0,1,1,1,1,0,0,0,0,0],\n",
    "                   'category': ['TP','TP','TN','TN','TN','FP','FP','FP','FP','FN','FN','FN','FN','FN']\n",
    "                  })\n",
    "\n",
    "display(df)\n",
    "pred = np.array( [df['preds_test']])\n",
    "label = np.array( [df['y_test']])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjDw9Fg9c21a"
   },
   "source": [
    "#### Sensitivity and Specificity for the patch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Kp4SJDWmc0L5",
    "outputId": "f8735867-131d-4d25-d84d-e008e9a68d5f"
   },
   "outputs": [],
   "source": [
    "# computing the sensitivity and specificity on that patch for expanding tumors. \n",
    "sensitivity, specificity = compute_class_sens_spec(patch_pred[0], y, 2)\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LuVZHUKnp4t"
   },
   "outputs": [],
   "source": [
    "# Sensitivity and specificity for each class\n",
    "def get_sens_spec_df(pred, label):\n",
    "    patch_metrics = pd.DataFrame(\n",
    "        columns = ['Edema', \n",
    "                   'Non-Enhancing Tumor', \n",
    "                   'Enhancing Tumor'], \n",
    "        index = ['Sensitivity',\n",
    "                 'Specificity'])\n",
    "    \n",
    "    for i, class_name in enumerate(patch_metrics.columns):\n",
    "        sens, spec = compute_class_sens_spec(pred, label, i)\n",
    "        patch_metrics.loc['Sensitivity', class_name] = round(sens,4)\n",
    "        patch_metrics.loc['Specificity', class_name] = round(spec,4)\n",
    "\n",
    "    return patch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lBPqWFmspQHj",
    "outputId": "7efafc97-ed71-4e28-ae74-4be3d5533322"
   },
   "outputs": [],
   "source": [
    "df = get_sens_spec_df(patch_pred[0], y)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoRrKnBmW0dk"
   },
   "source": [
    "<a name=\"5-3\"></a>\n",
    "## 5.3 Running on entire scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "18m8pkA9W0dt",
    "outputId": "673151b3-2120-4609-f0d6-154b47e8516a"
   },
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "pred = util.predict_and_viz(image, label, model, .5, loc=(130, 130, 77))                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PaiZrDrG7cHt"
   },
   "source": [
    "#### Checking how well the predictions did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T01:50:20.141287Z",
     "start_time": "2020-03-08T01:50:20.138316Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "H7pB-ZgPsl2N"
   },
   "outputs": [],
   "source": [
    "whole_scan_label = keras.utils.to_categorical(label, num_classes = 4)\n",
    "whole_scan_pred = pred\n",
    "\n",
    "# move axis to match shape expected in functions\n",
    "whole_scan_label = np.moveaxis(whole_scan_label, 3 ,0)[1:4]\n",
    "whole_scan_pred = np.moveaxis(whole_scan_pred, 3, 0)[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tpljPNBJ6k0k",
    "outputId": "adb78f68-6de9-4c8e-9ffb-163458a68b2f"
   },
   "outputs": [],
   "source": [
    "# compute sensitivity and specificity for each class just like before\n",
    "whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)\n",
    "\n",
    "print(whole_scan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "C1A4_Assignment.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
